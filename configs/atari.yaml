defaults:
  - algorithm: ddqn
  - env: atari
  - pruning: none
  - train: default
  - _self_

load_encoder_only: false

train:
  total_timesteps: 10_000_000
  buffer_size: 1_000_000

algorithm:
  network:
    encoder: nature_cnn

  learning_starts: 80_000
  optimizer:
    type: adam
    lr: 1.0e-4
    eps: 1.0e-8

  target_network_frequency: 5_000
  epsilon:
    decay_fraction: 0.2
    start: 1.0
    end: 0.05

wandb:
  enabled: true
  project: "rlp-25"
  group: "atari"
  entity: null
  tags: ["atari", "ddqn"]
  job_type: "train"

seed: 1
device: cuda
output_dir: "../models"