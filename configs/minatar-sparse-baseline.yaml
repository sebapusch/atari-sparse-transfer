# MinAtar Sparse Baseline (GMP)
# Self-contained configuration for MinAtar Sparse Baseline using GMP

defaults:
  - _self_

# Environment
env:
  id: "MinAtar/Breakout-v0"
  num_envs: 1
  capture_video: false
  frame_stack: 1

# Algorithm: DDQN
algorithm:
  name: "ddqn"
  network:
    encoder: "minatar_cnn"
    head: "linear"
    hidden_dim: 128
  
  gamma: 0.99
  tau: 1.0
  target_network_frequency: 1000
  batch_size: 32
  learning_starts: 5000
  train_frequency: 1
  
  epsilon:
    start: 1.0
    end: 0.01
    decay_fraction: 0.1
  
  optimizer:
    lr: 1e-4
    eps: 1e-8

# Training
train:
  total_timesteps: 5000000
  checkpoint_interval: 100000
  buffer_size: 100000

# Pruning: GMP
pruning:
  method: "gmp"
  initial_sparsity: 0.0
  final_sparsity: 0.8
  start_step: 100000      # Start pruning after some warmup
  end_step: 2500000       # Finish pruning halfway
  scheduler: "linear"     # or cubic
  update_frequency: 10000

# Global
seed: 1
device: "cuda"
output_dir: "outputs/minatar-sparse-baseline"

# W&B
wandb:
  enabled: true
  project: "rlp-25"
  group: "minatar-sparse"
  tags: ["minatar", "sparse", "gmp", "baseline"]
  job_type: "train"
  name: "minatar-sparse-gmp"

# Sweep Configuration
sweep:
  - seed: 1
  - seed: 2
  - seed: 3
